{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Demonstration\n",
    "\n",
    "This notebook demonstrates how to use the ML Pipeline for LGBM classification. It covers the basic functionality of each component and shows how they work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the ML pipeline\n",
    "from ml_pipeline import DataLoader, DataProcessor, ML_Pipeline\n",
    "\n",
    "# Set up paths\n",
    "TRAIN_CONFIG_PATH = \"data_config_train.json\"\n",
    "TEST_CONFIG_PATH = \"data_config_test.json\"\n",
    "MODEL_CONFIG_PATH = \"model_config.json\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"trained_model_outputs_path\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loader Demonstration\n",
    "\n",
    "First, let's demonstrate the DataLoader class which handles loading and validating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>target</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>bool</td>\n",
       "      <td>float</td>\n",
       "      <td>float</td>\n",
       "      <td>float</td>\n",
       "      <td>float</td>\n",
       "      <td>float</td>\n",
       "      <td>float</td>\n",
       "      <td>float</td>\n",
       "      <td>float</td>\n",
       "      <td>float</td>\n",
       "      <td>float</td>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imputation</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>unknown</td>\n",
       "      <td>mode</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_transformation</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>one-hot</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>super_category</td>\n",
       "      <td>1_id</td>\n",
       "      <td>1_id</td>\n",
       "      <td>2_DEPENDENT</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>variable_sign</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unnamed: 0    id_col  date_col       target    feature_0  \\\n",
       "0                     type  category  category         bool        float   \n",
       "1                      use         0         0            1            1   \n",
       "2               imputation   unknown   unknown      unknown         mean   \n",
       "3  category_transformation      None      None          NaN  Standardize   \n",
       "4           super_category      1_id      1_id  2_DEPENDENT   3_features   \n",
       "5            variable_sign         1         1            1            1   \n",
       "\n",
       "     feature_1    feature_2    feature_3    feature_4    feature_5  \\\n",
       "0        float        float        float        float        float   \n",
       "1            1            1            1            1            1   \n",
       "2         mean         mean         mean         mean         mean   \n",
       "3  Standardize  Standardize  Standardize  Standardize  Standardize   \n",
       "4   3_features   3_features   3_features   3_features   3_features   \n",
       "5            1            1            1            1            1   \n",
       "\n",
       "     feature_6    feature_7    feature_8    feature_9  feature_10  feature_11  \\\n",
       "0        float        float        float        float    category    category   \n",
       "1            1            1            1            1           1           1   \n",
       "2         mean         mean         mean      unknown        mode     unknown   \n",
       "3  Standardize  Standardize  Standardize  Standardize     one-hot        None   \n",
       "4   3_features   3_features   3_features   3_features  3_features  3_features   \n",
       "5            1            1            1            1           1           1   \n",
       "\n",
       "   feature_12  feature_13  \n",
       "0        bool        bool  \n",
       "1           1           1  \n",
       "2           0     unknown  \n",
       "3        None        None  \n",
       "4  3_features  3_features  \n",
       "5           1           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_excel(metadata_path)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>type</th>\n",
       "      <th>use</th>\n",
       "      <th>imputation</th>\n",
       "      <th>transformation</th>\n",
       "      <th>super_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_col</td>\n",
       "      <td>category</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>None</td>\n",
       "      <td>1_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date_col</td>\n",
       "      <td>category</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>None</td>\n",
       "      <td>1_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target</td>\n",
       "      <td>bool</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_DEPENDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_0</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_1</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature_2</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_3</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_4</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_6</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_7</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_8</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_9</td>\n",
       "      <td>float</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Standardize</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature_10</td>\n",
       "      <td>category</td>\n",
       "      <td>1</td>\n",
       "      <td>mode</td>\n",
       "      <td>one-hot</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feature_11</td>\n",
       "      <td>category</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>None</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feature_12</td>\n",
       "      <td>bool</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feature_13</td>\n",
       "      <td>bool</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>None</td>\n",
       "      <td>3_features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_name      type  use imputation transformation super_category\n",
       "0        id_col  category    0    unknown           None           1_id\n",
       "1      date_col  category    0    unknown           None           1_id\n",
       "2        target      bool    1    unknown            NaN    2_DEPENDENT\n",
       "3     feature_0     float    1       mean    Standardize     3_features\n",
       "4     feature_1     float    1       mean    Standardize     3_features\n",
       "5     feature_2     float    1       mean    Standardize     3_features\n",
       "6     feature_3     float    1       mean    Standardize     3_features\n",
       "7     feature_4     float    1       mean    Standardize     3_features\n",
       "8     feature_5     float    1       mean    Standardize     3_features\n",
       "9     feature_6     float    1       mean    Standardize     3_features\n",
       "10    feature_7     float    1       mean    Standardize     3_features\n",
       "11    feature_8     float    1       mean    Standardize     3_features\n",
       "12    feature_9     float    1    unknown    Standardize     3_features\n",
       "13   feature_10  category    1       mode        one-hot     3_features\n",
       "14   feature_11  category    1    unknown           None     3_features\n",
       "15   feature_12      bool    1          0           None     3_features\n",
       "16   feature_13      bool    1    unknown           None     3_features"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = \"feature_metadata.xlsx\"\n",
    "\n",
    "metadata_df = pd.read_excel(metadata_path)\n",
    "\n",
    "\n",
    "# Transform metadata_df to make it more usable\n",
    "# First row contains column types\n",
    "feature_types = metadata_df.iloc[0].to_dict()\n",
    "# Second row contains usage flags\n",
    "feature_use = metadata_df.iloc[1].to_dict()\n",
    "# Third row contains imputation methods\n",
    "feature_imputation = metadata_df.iloc[2].to_dict()\n",
    "# Fourth row contains category transformations\n",
    "feature_transformation = metadata_df.iloc[3].to_dict()\n",
    "# Fifth row contains super categories\n",
    "feature_super_category = metadata_df.iloc[4].to_dict()\n",
    "\n",
    "# Create a clean DataFrame for easier access\n",
    "feature_info = []\n",
    "for col in metadata_df.columns:\n",
    "    if col != \"Unnamed: 0\":\n",
    "        feature_info.append({\n",
    "            \"feature_name\": col,\n",
    "            \"type\": feature_types.get(col, \"\"),\n",
    "            \"use\": feature_use.get(col, 0),\n",
    "            \"imputation\": feature_imputation.get(col, \"\"),\n",
    "            \"transformation\": feature_transformation.get(col, \"\"),\n",
    "            \"super_category\": feature_super_category.get(col, \"\")\n",
    "        })\n",
    "\n",
    "pd.DataFrame(feature_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error parsing feature metadata file: Feature metadata file doesn't have the expected structure.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/ml_pipeline_second_try/bnbj_ml_pipeline/ml_pipeline/data_loader.py:128\u001b[0m, in \u001b[0;36mDataLoader._load_feature_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(col \u001b[38;5;129;01min\u001b[39;00m metadata_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory_transformation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuper_category\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature metadata file doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have the expected structure.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Transform metadata_df to make it more usable\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# First row contains column types\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Feature metadata file doesn't have the expected structure.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the data loader with training configuration\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_CONFIG_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_CONFIG_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get configurations\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data_config \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mget_data_config()\n",
      "File \u001b[0;32m~/Desktop/ml_pipeline_second_try/bnbj_ml_pipeline/ml_pipeline/data_loader.py:40\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, data_config_path, model_config_path)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_path\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Handle relative path starting with slash\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_path[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_feature_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Load input data\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_input_data()\n",
      "File \u001b[0;32m~/Desktop/ml_pipeline_second_try/bnbj_ml_pipeline/ml_pipeline/data_loader.py:160\u001b[0m, in \u001b[0;36mDataLoader._load_feature_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature metadata file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError parsing feature metadata file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Error parsing feature metadata file: Feature metadata file doesn't have the expected structure."
     ]
    }
   ],
   "source": [
    "# Initialize the data loader with training configuration\n",
    "data_loader = DataLoader(TRAIN_CONFIG_PATH, MODEL_CONFIG_PATH)\n",
    "\n",
    "# Get configurations\n",
    "data_config = data_loader.get_data_config()\n",
    "model_config = data_loader.get_model_config()\n",
    "\n",
    "print(\"Data config:\")\n",
    "for key, value in data_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nModel config:\")\n",
    "for key, value in model_config.items():\n",
    "    if key != \"hyperparameter_space\":  # Skip printing hyperparameter space for brevity\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get feature metadata\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m feature_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader\u001b[49m\u001b[38;5;241m.\u001b[39mget_feature_metadata()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature metadata summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Total features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(feature_metadata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Get feature metadata\n",
    "feature_metadata = data_loader.get_feature_metadata()\n",
    "print(\"Feature metadata summary:\")\n",
    "print(f\"  Total features: {len(feature_metadata)}\")\n",
    "print(\"\\nFeature metadata preview:\")\n",
    "display(feature_metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data with correct data types\n",
    "data = data_loader.get_data()\n",
    "print(\"Data summary:\")\n",
    "print(f\"  Shape: {data.shape}\")\n",
    "print(f\"  Columns: {list(data.columns)}\")\n",
    "print(\"\\nData preview:\")\n",
    "display(data.head())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "display(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processor Demonstration\n",
    "\n",
    "Next, let's demonstrate the DataProcessor class which handles preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data processor\n",
    "data_processor = DataProcessor(\n",
    "    feature_metadata=feature_metadata,\n",
    "    model_config=model_config,\n",
    "    output_dir=\"trained_model_outputs_path\"\n",
    ")\n",
    "\n",
    "# Print feature categorization\n",
    "print(\"Feature categorization:\")\n",
    "print(f\"  Numerical features: {data_processor.numerical_features}\")\n",
    "print(f\"  Categorical features: {data_processor.categorical_features}\")\n",
    "print(f\"  Binary features: {data_processor.binary_features}\")\n",
    "print(f\"  One-hot features: {data_processor.one_hot_features}\")\n",
    "print(f\"  Leave as NA features: {data_processor.leave_as_na_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folds for cross-validation\n",
    "fold_indices = data_processor.create_folds(data)\n",
    "print(f\"Created {len(fold_indices)} folds for cross-validation\")\n",
    "\n",
    "# Visualize the fold sizes\n",
    "fold_sizes = [(fold[0].shape[0], fold[1].shape[0]) for fold in fold_indices]\n",
    "df_fold_sizes = pd.DataFrame(fold_sizes, columns=['train_size', 'val_size'])\n",
    "df_fold_sizes['fold'] = range(len(fold_indices))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_fold_sizes['fold'], df_fold_sizes['train_size'], label='Train')\n",
    "plt.bar(df_fold_sizes['fold'], df_fold_sizes['val_size'], bottom=df_fold_sizes['train_size'], label='Validation')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Size')\n",
    "plt.title('Fold Sizes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "preprocessed_data = data_processor.preprocess_training_data(data, fold_indices)\n",
    "print(\"Preprocessed data:\")\n",
    "print(f\"  Original data shape: {preprocessed_data['original_data'].shape}\")\n",
    "print(f\"  Features shape: {preprocessed_data['X'].shape}\")\n",
    "print(f\"  Target shape: {preprocessed_data['y'].shape}\")\n",
    "print(f\"  Number of folds: {len(preprocessed_data['folds'])}\")\n",
    "\n",
    "# Print info for the first fold\n",
    "first_fold = preprocessed_data['folds'][0]\n",
    "print(\"\\nFirst fold:\")\n",
    "print(f\"  Fold index: {first_fold['fold_idx']}\")\n",
    "print(f\"  Training indices shape: {first_fold['train_idx'].shape}\")\n",
    "print(f\"  Validation indices shape: {first_fold['val_idx'].shape}\")\n",
    "print(f\"  X_train shape: {first_fold['X_train'].shape}\")\n",
    "print(f\"  X_train_transformed shape: {first_fold['X_train_transformed'].shape}\")\n",
    "print(f\"  X_val shape: {first_fold['X_val'].shape}\")\n",
    "print(f\"  X_val_transformed shape: {first_fold['X_val_transformed'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the full dataset\n",
    "X_transformed, y = data_processor.fit_transform_full_dataset(data)\n",
    "print(\"Full dataset transformation:\")\n",
    "print(f\"  X_transformed shape: {X_transformed.shape}\")\n",
    "print(f\"  y shape: {y.shape}\")\n",
    "\n",
    "# Save the preprocessor\n",
    "preprocessor_path = data_processor.save_preprocessor()\n",
    "print(f\"Preprocessor saved to: {preprocessor_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ML Pipeline Demonstration\n",
    "\n",
    "Finally, let's demonstrate the full ML_Pipeline class which integrates data loading, preprocessing, and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ML pipeline for training\n",
    "pipeline = ML_Pipeline(MODEL_CONFIG_PATH, TRAIN_CONFIG_PATH)\n",
    "print(f\"ML Pipeline initialized for {'training' if pipeline.is_training else 'testing'}\")\n",
    "\n",
    "# Run the pipeline for training\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model performances\n",
    "performances = pipeline.get_model_performances()\n",
    "print(\"Model performances:\")\n",
    "for perf in performances:\n",
    "    print(f\"  Fold {perf['fold_idx']}: {perf['performance']}\")\n",
    "\n",
    "# Visualize the performances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(performances)), [p['performance'] for p in performances])\n",
    "plt.axhline(y=np.mean([p['performance'] for p in performances]), color='r', linestyle='-', label='Mean')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Model Performances Across Folds')\n",
    "plt.xticks(range(len(performances)), [f\"Fold {p['fold_idx']}\" for p in performances])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now initialize the ML pipeline for testing\n",
    "test_pipeline = ML_Pipeline(MODEL_CONFIG_PATH, TEST_CONFIG_PATH)\n",
    "print(f\"ML Pipeline initialized for {'training' if test_pipeline.is_training else 'testing'}\")\n",
    "\n",
    "# Run the pipeline for testing\n",
    "test_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the predictions\n",
    "predictions_path = test_pipeline.data_config.get(\"predictions_output_path\", \"\")\n",
    "if os.path.exists(predictions_path):\n",
    "    predictions_df = pd.read_csv(predictions_path)\n",
    "    print(\"Predictions:\")\n",
    "    print(f\"  Shape: {predictions_df.shape}\")\n",
    "    print(f\"  Columns: {list(predictions_df.columns)}\")\n",
    "    display(predictions_df.head())\n",
    "    \n",
    "    # Visualize the predictions distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(predictions_df['prediction'], bins=20)\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Predictions Distribution')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Predictions file not found at: {predictions_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optional: Feature Importance Analysis\n",
    "\n",
    "If desired, we can analyze the feature importances from the trained LGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "import pickle\n",
    "\n",
    "model_path = os.path.join(\"trained_model_outputs_path\", \"target_classification_lgbm.pkl\")\n",
    "if os.path.exists(model_path):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importance = model.feature_importance()\n",
    "    \n",
    "    # Map feature indices to feature names\n",
    "    feature_indices = list(range(len(feature_importance)))\n",
    "    \n",
    "    # Create a dataframe of feature importances\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature_idx': feature_indices,\n",
    "        'importance': feature_importance\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Display feature importances\n",
    "    print(\"Feature importances:\")\n",
    "    display(importance_df.head(10))\n",
    "    \n",
    "    # Visualize feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(importance_df['feature_idx'].head(20), importance_df['importance'].head(20))\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.xticks(importance_df['feature_idx'].head(20))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Model file not found at: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
